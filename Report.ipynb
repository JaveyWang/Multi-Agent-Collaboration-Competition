{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "\n",
    "## 1. Folder Tree\n",
    "**Report.ipynb** - Describing the algorithm of Multi-Agent DDPG(MADDPG) for solving the \"Tennis\" task.\n",
    "\n",
    "**main.ipynb** - Containing the training code of the MADDPG algorithm and showing the return of each episode along the \n",
    "training step.\n",
    "\n",
    "**model.py&utils.py** - Containing the network architechture\n",
    "\n",
    "**MADDPG.ckpt** - The trained model weights.\n",
    "\n",
    "**MADDPG_max_scores.csv** - results.\n",
    "\n",
    "## 2. Approach\n",
    "Due to the fact that it is often unstable to train multiple agent in a environment. I implement the MADDPG algorithm that partly solve this problem. MADDPG is extended from the DDPG algorithm, and constructed by Actor-Critic architecture. The diffrence between them is use the so called \"decentralized actor\" with the \"centralized critic\", which better fit the multi agent problem, see figure below.\n",
    "<img src='figure/multi-agent-actor-critic.png' width=30% height=30%>\n",
    "Next, I will discussed my implementation of this algorithm.\n",
    "\n",
    "### 2.1 Actor-Critic\n",
    "First, I create two decentralized actor and a centralized critic along with their target networks for two agent. The code can be found in \"Agent\" class of model.py.\n",
    "```python\n",
    "        self.actor_local_0 = Actor(state_size, action_size, embed_dim, seed).to(\n",
    "            device)\n",
    "        self.actor_target_0 = Actor(state_size, action_size, embed_dim, seed).to(\n",
    "            device)\n",
    "        self.actor_optimizer_0 = optim.Adam(self.actor_local_0.parameters(), lr=lr)\n",
    "\n",
    "        self.actor_local_1 = Actor(state_size, action_size, embed_dim, seed).to(\n",
    "            device)\n",
    "        self.actor_target_1 = Actor(state_size, action_size, embed_dim, seed).to(\n",
    "            device)\n",
    "        self.actor_optimizer_1 = optim.Adam(self.actor_local_1.parameters(), lr=lr)\n",
    "\n",
    "        self.critic_local = Critic(2 * state_size, 2 * action_size, embed_dim, seed).to(\n",
    "            device)\n",
    "        self.critic_target = Critic(2 * state_size, 2 * action_size, embed_dim, seed).to(\n",
    "            device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=lr)\n",
    "```\n",
    "\n",
    "### 2.2 Time-Correlated Replay Buffer\n",
    "In the last two project, we often save one step experience like (S, A, R, S') to the replay buffer, and then randomly sample a batch from the replay buffer to train the agent. This implementation may suit for one-step TD update algorithm. However, whatif we want to implement n-step TD($\\gamma$) algorithm to better trade off the bias and variance of the estamation of the Q value. So in my case, I implement a time-correlated replay buffer, which imply that the agent save a continuous episode at a time in the replay buffer, and then sample the whole experiences at the training time to train the model. Note, in my implementation, I find it is good enough to train the model using one-step TD learning, so n-step TD learning can be the future work, which may perform better.\n",
    "\n",
    "### 2.3 Hyperparameters\n",
    "\n",
    "#### Ornstein-Uhlenbeck process\n",
    "I addressed the exploration and exploitation dilemma using the Ornstein-Uhlenbeck process, which add a certain noise to the action at each timestep. The characteristic of the OU process is that its noise is dependent on the previous timestep, which is infected by three parameters:\n",
    "\n",
    "1) $\\mu$: the long-running mean. Default: 0\n",
    "\n",
    "2) $\\theta$: the speed of mean reversion. Default: 0.15\n",
    "\n",
    "3) $\\sigma$: the volatility parameter. Default: 0.2\n",
    "\n",
    "Furthermore, we linearly decay the noise for more exploitation and less exploration throungh the training process. \n",
    "\n",
    "```python\n",
    "EPS_START = 5.0   # initial value for epsilon in noise decay process in Agent.act()\n",
    "EPS_EP_END = 500  # episode to end the noise decay process\n",
    "EPS_FINAL = 0     # final value for epsilon after decay\n",
    "```\n",
    "#### Other hyperparameters\n",
    "```python\n",
    "BATCH_SIZE = 16         # Batch size of training samples.\n",
    "EMBED_DIM = 256         # Embed size of the agent.\n",
    "NUM_EPISODES = 2500     # Maximum training episodes.\n",
    "LOG_INTERVAL = 128      # The interval to print the average scores\n",
    "LEARN_NUM = 16          # Learning times at each episode.\n",
    "BUFFER_SIZE = int(1e6)  # The buffer size of the replay buffer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum average scores is 1.60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "# Load experimental results.\n",
    "scores = pd.read_csv('MADDPG_max_scores.csv')['0'].values\n",
    "\n",
    "# Visualize the return curve.\n",
    "avg_scores = []\n",
    "for i in range(100, len(scores)):\n",
    "    avg_scores.append(np.mean(scores[i-100:i]))\n",
    "    \n",
    "plt.plot(scores)\n",
    "plt.plot(avg_scores)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Analize the results.\n",
    "print(f'The maximum average scores is {np.max(avg_scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure, we can see that our agent accomplished an average score of 1.60. And it first hit an average score of +0.5 at around 2000 episodes. To this end, we solve this task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work\n",
    "**1. N-step TD Learning**\n",
    "\n",
    "I have implemented a time time-correlated replay buffer, so I can use a n-step return to estimate the value funciton, which may find a better trade off between bias and variance than one-step return. Here is the definition of the n-step return:\n",
    "\n",
    "$G_{t:t+n}=R_t + \\gamma R_{t+1} + ... + \\gamma^{n-1} R_{t+n} + \\gamma^{n} V_{t+n}$\n",
    "\n",
    "**2. Prioritized Experience Replay**\n",
    "\n",
    "Instead of sample experiences randomly, we can perform prioritized experience replay (PER). PER samples the experiences depending on their importance, which is correlated to the TD-error. The higher the TD-error, the more likely it is to be sampled. Therefore, by performing the PER, the agent may become more efficient to learn in environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Agent Play Tennis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"./Tennis.app\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import Agent\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 16         # Batch size of training samples.\n",
    "EMBED_DIM = 256         # Embed size of the agent.\n",
    "NUM_EPISODES = 2500     # Maximum training episodes.\n",
    "LOG_INTERVAL = 128      # The interval to print the average scores\n",
    "LEARN_NUM = 16          # Learning times at each episode.\n",
    "BUFFER_SIZE = int(1e6)  # The buffer size of the replay buffer.\n",
    "\n",
    "agent = Agent(state_size, action_size, buffer_size=BUFFER_SIZE)\n",
    "ckpt = torch.load('./MADDPG.ckpt')\n",
    "agent.load_state_dict(ckpt['agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:59<01:55, 57.95s/it]"
     ]
    }
   ],
   "source": [
    "NUM_EPISODES = 5\n",
    "\n",
    "with tqdm(total=NUM_EPISODES) as pbar:\n",
    "    for i_episode in range(NUM_EPISODES):\n",
    "        pbar.update(1)\n",
    "        env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "        states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "        while True:\n",
    "            actions = agent.act(states, isnoise=False)         # select an action (for each agent)\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = np.array(env_info.rewards)               # get reward (for each agent)\n",
    "            dones = np.array(env_info.local_done)              # see if episode finished\n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            \n",
    "            states = next_states\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure/MultiAgentPlayTennis.gif\" width=\"70%\" align=\"top-left\" alt=\"\" title=\"Robot Ping Pong\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
